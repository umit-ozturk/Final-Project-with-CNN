{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model_for_colab.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ga4ASyVmX2g9","colab_type":"code","outputId":"c7898505-4417-4f27-b1f9-9de564fa8e6d","executionInfo":{"status":"ok","timestamp":1558553603880,"user_tz":-180,"elapsed":114041,"user":{"displayName":"Yusuf Alper Sarı","photoUrl":"https://lh4.googleusercontent.com/-nFHkEPxWGyM/AAAAAAAAAAI/AAAAAAAAAAc/qr2h1NOhmVc/s64/photo.jpg","userId":"04783113797674990270"}},"colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","!pip3 install -q keras"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 130824 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BJAHLDg-X2hM","colab_type":"code","colab":{}},"source":["import os\n","\n","os.chdir(\"/content/drive/My Drive/CNN-Face-Recognation/src/\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CW65yMz1X2hU","colab_type":"code","outputId":"57ea08da-2f73-42f6-c12b-b90384a93cf0","executionInfo":{"status":"ok","timestamp":1558554267889,"user_tz":-180,"elapsed":6458,"user":{"displayName":"Yusuf Alper Sarı","photoUrl":"https://lh4.googleusercontent.com/-nFHkEPxWGyM/AAAAAAAAAAI/AAAAAAAAAAc/qr2h1NOhmVc/s64/photo.jpg","userId":"04783113797674990270"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Activation, Conv2D\n","from keras.layers import BatchNormalization\n","from keras.layers import GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import MaxPooling2D\n","from keras.layers import SeparableConv2D\n","from keras import layers\n","from keras.regularizers import l2\n","import pandas as pd\n","import cv2\n","import numpy as np\n","\n","!pip3 install pandas"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n","Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.3)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sN0EZ1HmX2he","colab_type":"code","outputId":"b4c022e3-9511-4a55-f873-87f47bd2e34b","executionInfo":{"status":"ok","timestamp":1558556294315,"user_tz":-180,"elapsed":2021634,"user":{"displayName":"Yusuf Alper Sarı","photoUrl":"https://lh4.googleusercontent.com/-nFHkEPxWGyM/AAAAAAAAAAI/AAAAAAAAAAc/qr2h1NOhmVc/s64/photo.jpg","userId":"04783113797674990270"}},"colab":{"base_uri":"https://localhost:8080/","height":8425}},"source":["!python retrain_classifier.py"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","2019-05-22 19:44:37.452724: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-05-22 19:44:37.453149: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2011340 executing computations on platform Host. Devices:\n","2019-05-22 19:44:37.453202: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-05-22 19:44:37.705498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-05-22 19:44:37.706083: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2010f20 executing computations on platform CUDA. Devices:\n","2019-05-22 19:44:37.706149: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-05-22 19:44:37.706574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.73GiB freeMemory: 14.60GiB\n","2019-05-22 19:44:37.706615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2019-05-22 19:44:39.074890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-05-22 19:44:39.074953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2019-05-22 19:44:39.074965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2019-05-22 19:44:39.075215: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-05-22 19:44:39.075297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 31, 31, 32)   288         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 31, 31, 32)   128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 31, 31, 32)   0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 29, 29, 64)   18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 29, 29, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 29, 29, 64)   0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","separable_conv2d_1 (SeparableCo (None, 29, 29, 128)  8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 29, 29, 128)  512         separable_conv2d_1[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 29, 29, 128)  0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","separable_conv2d_2 (SeparableCo (None, 29, 29, 128)  17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 29, 29, 128)  512         separable_conv2d_2[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 15, 15, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 15, 15, 128)  512         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 15, 15, 128)  0           max_pooling2d_1[0][0]            \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 15, 15, 128)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_3 (SeparableCo (None, 15, 15, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 15, 15, 256)  1024        separable_conv2d_3[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 15, 15, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","separable_conv2d_4 (SeparableCo (None, 15, 15, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 15, 15, 256)  1024        separable_conv2d_4[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 8, 8, 256)    32768       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 8, 8, 256)    1024        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 8, 8, 256)    0           max_pooling2d_2[0][0]            \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 8, 8, 7)      16135       add_2[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n","==================================================================================================\n","Total params: 208,871\n","Trainable params: 206,375\n","Non-trainable params: 2,496\n","__________________________________________________________________________________________________\n","Training dataset: fer2013\n","/content/drive/My Drive/CNN-Face-Recognation/src/utils/datasets.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n","  emotions = pd.get_dummies(data['emotion']).as_matrix()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/10000\n","898/897 [==============================] - 25s 28ms/step - loss: 1.6435 - acc: 0.4226 - val_loss: 1.4371 - val_acc: 0.4585\n","\n","Epoch 00001: val_loss improved from inf to 1.43714, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.01-0.46.hdf5\n","Epoch 2/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.3633 - acc: 0.4833 - val_loss: 1.3444 - val_acc: 0.4889\n","\n","Epoch 00002: val_loss improved from 1.43714 to 1.34439, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.02-0.49.hdf5\n","Epoch 3/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.3164 - acc: 0.5023 - val_loss: 1.2962 - val_acc: 0.5103\n","\n","Epoch 00003: val_loss improved from 1.34439 to 1.29615, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.03-0.51.hdf5\n","Epoch 4/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 1.2750 - acc: 0.5196 - val_loss: 1.2484 - val_acc: 0.5301\n","\n","Epoch 00004: val_loss improved from 1.29615 to 1.24837, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.04-0.53.hdf5\n","Epoch 5/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.2475 - acc: 0.5291 - val_loss: 1.2282 - val_acc: 0.5394\n","\n","Epoch 00005: val_loss improved from 1.24837 to 1.22817, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.05-0.54.hdf5\n","Epoch 6/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.2234 - acc: 0.5354 - val_loss: 1.1984 - val_acc: 0.5521\n","\n","Epoch 00006: val_loss improved from 1.22817 to 1.19835, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.06-0.55.hdf5\n","Epoch 7/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.1996 - acc: 0.5468 - val_loss: 1.2661 - val_acc: 0.5326\n","\n","Epoch 00007: val_loss did not improve from 1.19835\n","Epoch 8/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.1821 - acc: 0.5541 - val_loss: 1.2375 - val_acc: 0.5426\n","\n","Epoch 00008: val_loss did not improve from 1.19835\n","Epoch 9/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.1632 - acc: 0.5642 - val_loss: 1.2033 - val_acc: 0.5564\n","\n","Epoch 00009: val_loss did not improve from 1.19835\n","Epoch 10/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.1460 - acc: 0.5713 - val_loss: 1.1891 - val_acc: 0.5610\n","\n","Epoch 00010: val_loss improved from 1.19835 to 1.18914, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.10-0.56.hdf5\n","Epoch 11/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.1369 - acc: 0.5735 - val_loss: 1.2007 - val_acc: 0.5542\n","\n","Epoch 00011: val_loss did not improve from 1.18914\n","Epoch 12/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.1266 - acc: 0.5772 - val_loss: 1.1760 - val_acc: 0.5639\n","\n","Epoch 00012: val_loss improved from 1.18914 to 1.17599, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.12-0.56.hdf5\n","Epoch 13/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.1178 - acc: 0.5806 - val_loss: 1.1931 - val_acc: 0.5617\n","\n","Epoch 00013: val_loss did not improve from 1.17599\n","Epoch 14/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.1037 - acc: 0.5840 - val_loss: 1.1318 - val_acc: 0.5794\n","\n","Epoch 00014: val_loss improved from 1.17599 to 1.13183, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.14-0.58.hdf5\n","Epoch 15/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.0959 - acc: 0.5909 - val_loss: 1.1950 - val_acc: 0.5651\n","\n","Epoch 00015: val_loss did not improve from 1.13183\n","Epoch 16/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.0823 - acc: 0.5935 - val_loss: 1.1429 - val_acc: 0.5791\n","\n","Epoch 00016: val_loss did not improve from 1.13183\n","Epoch 17/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 1.0745 - acc: 0.5966 - val_loss: 1.1702 - val_acc: 0.5681\n","\n","Epoch 00017: val_loss did not improve from 1.13183\n","Epoch 18/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.0688 - acc: 0.5989 - val_loss: 1.1265 - val_acc: 0.5854\n","\n","Epoch 00018: val_loss improved from 1.13183 to 1.12652, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.18-0.59.hdf5\n","Epoch 19/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.0604 - acc: 0.6029 - val_loss: 1.1815 - val_acc: 0.5634\n","\n","Epoch 00019: val_loss did not improve from 1.12652\n","Epoch 20/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 1.0520 - acc: 0.6042 - val_loss: 1.1211 - val_acc: 0.5880\n","\n","Epoch 00020: val_loss improved from 1.12652 to 1.12110, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.20-0.59.hdf5\n","Epoch 21/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 1.0415 - acc: 0.6127 - val_loss: 1.2077 - val_acc: 0.5704\n","\n","Epoch 00021: val_loss did not improve from 1.12110\n","Epoch 22/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.0362 - acc: 0.6140 - val_loss: 1.1382 - val_acc: 0.5847\n","\n","Epoch 00022: val_loss did not improve from 1.12110\n","Epoch 23/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.0306 - acc: 0.6143 - val_loss: 1.0902 - val_acc: 0.5965\n","\n","Epoch 00023: val_loss improved from 1.12110 to 1.09018, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.23-0.60.hdf5\n","Epoch 24/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 1.0244 - acc: 0.6179 - val_loss: 1.1174 - val_acc: 0.5936\n","\n","Epoch 00024: val_loss did not improve from 1.09018\n","Epoch 25/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 1.0209 - acc: 0.6193 - val_loss: 1.1166 - val_acc: 0.5949\n","\n","Epoch 00025: val_loss did not improve from 1.09018\n","Epoch 26/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.0132 - acc: 0.6212 - val_loss: 1.0736 - val_acc: 0.6034\n","\n","Epoch 00026: val_loss improved from 1.09018 to 1.07355, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.26-0.60.hdf5\n","Epoch 27/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 1.0041 - acc: 0.6249 - val_loss: 1.0917 - val_acc: 0.6016\n","\n","Epoch 00027: val_loss did not improve from 1.07355\n","Epoch 28/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 1.0015 - acc: 0.6267 - val_loss: 1.1667 - val_acc: 0.5794\n","\n","Epoch 00028: val_loss did not improve from 1.07355\n","Epoch 29/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9981 - acc: 0.6274 - val_loss: 1.1996 - val_acc: 0.5681\n","\n","Epoch 00029: val_loss did not improve from 1.07355\n","Epoch 30/10000\n","898/897 [==============================] - 20s 22ms/step - loss: 0.9891 - acc: 0.6295 - val_loss: 1.1084 - val_acc: 0.5893\n","\n","Epoch 00030: val_loss did not improve from 1.07355\n","Epoch 31/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9888 - acc: 0.6310 - val_loss: 1.0945 - val_acc: 0.6038\n","\n","Epoch 00031: val_loss did not improve from 1.07355\n","Epoch 32/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9756 - acc: 0.6378 - val_loss: 1.1072 - val_acc: 0.5961\n","\n","Epoch 00032: val_loss did not improve from 1.07355\n","Epoch 33/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9717 - acc: 0.6367 - val_loss: 1.1994 - val_acc: 0.5818\n","\n","Epoch 00033: val_loss did not improve from 1.07355\n","Epoch 34/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9719 - acc: 0.6380 - val_loss: 1.0780 - val_acc: 0.6128\n","\n","Epoch 00034: val_loss did not improve from 1.07355\n","Epoch 35/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9653 - acc: 0.6408 - val_loss: 1.0962 - val_acc: 0.6073\n","\n","Epoch 00035: val_loss did not improve from 1.07355\n","Epoch 36/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9622 - acc: 0.6435 - val_loss: 1.1221 - val_acc: 0.6017\n","\n","Epoch 00036: val_loss did not improve from 1.07355\n","Epoch 37/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9510 - acc: 0.6468 - val_loss: 1.0984 - val_acc: 0.6038\n","\n","Epoch 00037: val_loss did not improve from 1.07355\n","Epoch 38/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9556 - acc: 0.6453 - val_loss: 1.0748 - val_acc: 0.6112\n","\n","Epoch 00038: val_loss did not improve from 1.07355\n","\n","Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 39/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9233 - acc: 0.6573 - val_loss: 1.0410 - val_acc: 0.6234\n","\n","Epoch 00039: val_loss improved from 1.07355 to 1.04100, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.39-0.62.hdf5\n","Epoch 40/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9195 - acc: 0.6584 - val_loss: 1.0393 - val_acc: 0.6264\n","\n","Epoch 00040: val_loss improved from 1.04100 to 1.03932, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.40-0.63.hdf5\n","Epoch 41/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9189 - acc: 0.6598 - val_loss: 1.0471 - val_acc: 0.6211\n","\n","Epoch 00041: val_loss did not improve from 1.03932\n","Epoch 42/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9191 - acc: 0.6590 - val_loss: 1.0417 - val_acc: 0.6261\n","\n","Epoch 00042: val_loss did not improve from 1.03932\n","Epoch 43/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9152 - acc: 0.6610 - val_loss: 1.0418 - val_acc: 0.6232\n","\n","Epoch 00043: val_loss did not improve from 1.03932\n","Epoch 44/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9167 - acc: 0.6597 - val_loss: 1.0450 - val_acc: 0.6232\n","\n","Epoch 00044: val_loss did not improve from 1.03932\n","Epoch 45/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9156 - acc: 0.6607 - val_loss: 1.0382 - val_acc: 0.6257\n","\n","Epoch 00045: val_loss improved from 1.03932 to 1.03820, saving model to ../trained_models/emotion_models/fer2013_mini_XCEPTION.45-0.63.hdf5\n","Epoch 46/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9161 - acc: 0.6604 - val_loss: 1.0427 - val_acc: 0.6248\n","\n","Epoch 00046: val_loss did not improve from 1.03820\n","Epoch 47/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9187 - acc: 0.6596 - val_loss: 1.0441 - val_acc: 0.6225\n","\n","Epoch 00047: val_loss did not improve from 1.03820\n","Epoch 48/10000\n","898/897 [==============================] - 22s 25ms/step - loss: 0.9113 - acc: 0.6644 - val_loss: 1.0422 - val_acc: 0.6258\n","\n","Epoch 00048: val_loss did not improve from 1.03820\n","Epoch 49/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 0.9105 - acc: 0.6614 - val_loss: 1.0409 - val_acc: 0.6241\n","\n","Epoch 00049: val_loss did not improve from 1.03820\n","Epoch 50/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9094 - acc: 0.6609 - val_loss: 1.0444 - val_acc: 0.6257\n","\n","Epoch 00050: val_loss did not improve from 1.03820\n","Epoch 51/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9136 - acc: 0.6622 - val_loss: 1.0439 - val_acc: 0.6243\n","\n","Epoch 00051: val_loss did not improve from 1.03820\n","Epoch 52/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 0.9128 - acc: 0.6619 - val_loss: 1.0419 - val_acc: 0.6250\n","\n","Epoch 00052: val_loss did not improve from 1.03820\n","Epoch 53/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9069 - acc: 0.6651 - val_loss: 1.0430 - val_acc: 0.6252\n","\n","Epoch 00053: val_loss did not improve from 1.03820\n","Epoch 54/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9125 - acc: 0.6638 - val_loss: 1.0445 - val_acc: 0.6236\n","\n","Epoch 00054: val_loss did not improve from 1.03820\n","Epoch 55/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 0.9082 - acc: 0.6642 - val_loss: 1.0420 - val_acc: 0.6239\n","\n","Epoch 00055: val_loss did not improve from 1.03820\n","Epoch 56/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9076 - acc: 0.6655 - val_loss: 1.0411 - val_acc: 0.6241\n","\n","Epoch 00056: val_loss did not improve from 1.03820\n","Epoch 57/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9036 - acc: 0.6661 - val_loss: 1.0424 - val_acc: 0.6240\n","\n","Epoch 00057: val_loss did not improve from 1.03820\n","\n","Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 58/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9045 - acc: 0.6656 - val_loss: 1.0422 - val_acc: 0.6244\n","\n","Epoch 00058: val_loss did not improve from 1.03820\n","Epoch 59/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9030 - acc: 0.6647 - val_loss: 1.0429 - val_acc: 0.6265\n","\n","Epoch 00059: val_loss did not improve from 1.03820\n","Epoch 60/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9016 - acc: 0.6656 - val_loss: 1.0419 - val_acc: 0.6258\n","\n","Epoch 00060: val_loss did not improve from 1.03820\n","Epoch 61/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9022 - acc: 0.6667 - val_loss: 1.0415 - val_acc: 0.6259\n","\n","Epoch 00061: val_loss did not improve from 1.03820\n","Epoch 62/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9007 - acc: 0.6688 - val_loss: 1.0424 - val_acc: 0.6264\n","\n","Epoch 00062: val_loss did not improve from 1.03820\n","Epoch 63/10000\n","898/897 [==============================] - 22s 25ms/step - loss: 0.9016 - acc: 0.6661 - val_loss: 1.0412 - val_acc: 0.6255\n","\n","Epoch 00063: val_loss did not improve from 1.03820\n","Epoch 64/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9049 - acc: 0.6645 - val_loss: 1.0416 - val_acc: 0.6271\n","\n","Epoch 00064: val_loss did not improve from 1.03820\n","Epoch 65/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9040 - acc: 0.6693 - val_loss: 1.0431 - val_acc: 0.6261\n","\n","Epoch 00065: val_loss did not improve from 1.03820\n","Epoch 66/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9072 - acc: 0.6654 - val_loss: 1.0420 - val_acc: 0.6258\n","\n","Epoch 00066: val_loss did not improve from 1.03820\n","Epoch 67/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9041 - acc: 0.6698 - val_loss: 1.0414 - val_acc: 0.6258\n","\n","Epoch 00067: val_loss did not improve from 1.03820\n","Epoch 68/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 0.9001 - acc: 0.6660 - val_loss: 1.0407 - val_acc: 0.6269\n","\n","Epoch 00068: val_loss did not improve from 1.03820\n","Epoch 69/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.8985 - acc: 0.6684 - val_loss: 1.0422 - val_acc: 0.6255\n","\n","Epoch 00069: val_loss did not improve from 1.03820\n","\n","Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 70/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.8991 - acc: 0.6672 - val_loss: 1.0424 - val_acc: 0.6265\n","\n","Epoch 00070: val_loss did not improve from 1.03820\n","Epoch 71/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9035 - acc: 0.6654 - val_loss: 1.0430 - val_acc: 0.6257\n","\n","Epoch 00071: val_loss did not improve from 1.03820\n","Epoch 72/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9046 - acc: 0.6668 - val_loss: 1.0414 - val_acc: 0.6261\n","\n","Epoch 00072: val_loss did not improve from 1.03820\n","Epoch 73/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9049 - acc: 0.6641 - val_loss: 1.0407 - val_acc: 0.6265\n","\n","Epoch 00073: val_loss did not improve from 1.03820\n","Epoch 74/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9027 - acc: 0.6646 - val_loss: 1.0410 - val_acc: 0.6268\n","\n","Epoch 00074: val_loss did not improve from 1.03820\n","Epoch 75/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9040 - acc: 0.6662 - val_loss: 1.0413 - val_acc: 0.6266\n","\n","Epoch 00075: val_loss did not improve from 1.03820\n","Epoch 76/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.8990 - acc: 0.6685 - val_loss: 1.0419 - val_acc: 0.6265\n","\n","Epoch 00076: val_loss did not improve from 1.03820\n","Epoch 77/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9005 - acc: 0.6680 - val_loss: 1.0418 - val_acc: 0.6254\n","\n","Epoch 00077: val_loss did not improve from 1.03820\n","Epoch 78/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.8981 - acc: 0.6681 - val_loss: 1.0427 - val_acc: 0.6251\n","\n","Epoch 00078: val_loss did not improve from 1.03820\n","Epoch 79/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 0.9058 - acc: 0.6653 - val_loss: 1.0420 - val_acc: 0.6261\n","\n","Epoch 00079: val_loss did not improve from 1.03820\n","Epoch 80/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9002 - acc: 0.6660 - val_loss: 1.0424 - val_acc: 0.6262\n","\n","Epoch 00080: val_loss did not improve from 1.03820\n","Epoch 81/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9039 - acc: 0.6652 - val_loss: 1.0417 - val_acc: 0.6259\n","\n","Epoch 00081: val_loss did not improve from 1.03820\n","\n","Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n","Epoch 82/10000\n","898/897 [==============================] - 21s 24ms/step - loss: 0.9019 - acc: 0.6631 - val_loss: 1.0417 - val_acc: 0.6248\n","\n","Epoch 00082: val_loss did not improve from 1.03820\n","Epoch 83/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9049 - acc: 0.6696 - val_loss: 1.0420 - val_acc: 0.6250\n","\n","Epoch 00083: val_loss did not improve from 1.03820\n","Epoch 84/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9024 - acc: 0.6662 - val_loss: 1.0420 - val_acc: 0.6258\n","\n","Epoch 00084: val_loss did not improve from 1.03820\n","Epoch 85/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9000 - acc: 0.6659 - val_loss: 1.0417 - val_acc: 0.6255\n","\n","Epoch 00085: val_loss did not improve from 1.03820\n","Epoch 86/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9029 - acc: 0.6643 - val_loss: 1.0408 - val_acc: 0.6265\n","\n","Epoch 00086: val_loss did not improve from 1.03820\n","Epoch 87/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9031 - acc: 0.6657 - val_loss: 1.0433 - val_acc: 0.6250\n","\n","Epoch 00087: val_loss did not improve from 1.03820\n","Epoch 88/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9013 - acc: 0.6678 - val_loss: 1.0419 - val_acc: 0.6264\n","\n","Epoch 00088: val_loss did not improve from 1.03820\n","Epoch 89/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9025 - acc: 0.6671 - val_loss: 1.0423 - val_acc: 0.6257\n","\n","Epoch 00089: val_loss did not improve from 1.03820\n","Epoch 90/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9010 - acc: 0.6670 - val_loss: 1.0421 - val_acc: 0.6255\n","\n","Epoch 00090: val_loss did not improve from 1.03820\n","Epoch 91/10000\n","898/897 [==============================] - 21s 23ms/step - loss: 0.9020 - acc: 0.6664 - val_loss: 1.0420 - val_acc: 0.6251\n","\n","Epoch 00091: val_loss did not improve from 1.03820\n","Epoch 92/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.9066 - acc: 0.6650 - val_loss: 1.0409 - val_acc: 0.6262\n","\n","Epoch 00092: val_loss did not improve from 1.03820\n","Epoch 93/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.8998 - acc: 0.6660 - val_loss: 1.0410 - val_acc: 0.6266\n","\n","Epoch 00093: val_loss did not improve from 1.03820\n","\n","Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n","Epoch 94/10000\n","898/897 [==============================] - 22s 24ms/step - loss: 0.9032 - acc: 0.6685 - val_loss: 1.0415 - val_acc: 0.6257\n","\n","Epoch 00094: val_loss did not improve from 1.03820\n","Epoch 95/10000\n","898/897 [==============================] - 20s 23ms/step - loss: 0.8992 - acc: 0.6650 - val_loss: 1.0412 - val_acc: 0.6262\n","\n","Epoch 00095: val_loss did not improve from 1.03820\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NuP9C4cLX2hm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEgHef8mX2hr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}